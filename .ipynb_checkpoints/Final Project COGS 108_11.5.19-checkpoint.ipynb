{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Safety in San Diego County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Member IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fill in your background and prior work here\n",
    "\n",
    "References (include links):\n",
    "\n",
    "1)\n",
    "2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in your dataset information here\n",
    "\n",
    "(Copy this information for each dataset)\n",
    "\n",
    "Dataset Name:\n",
    "Link to the dataset:\n",
    "Number of observations:\n",
    "1-2 sentences describing each dataset.\n",
    "\n",
    "If you plan to use multiple datasets, add 1-2 sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For data cleaning\n",
    "import string\n",
    "\n",
    "# Display plots directly in the notebook instead of in a new window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure libraries\n",
    "# The seaborn library makes plots look nicer\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "\n",
    "# Round decimals when displaying DataFrames\n",
    "pd.set_option('precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (7,9,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read police stops Data Frame\n",
    "df_police_stops = pd.read_csv(\"datasets/police_stops/ripa_stops_datasd_v1.csv\")\n",
    "\n",
    "# Read collisions Data Frame\n",
    "df_collisions = pd.read_csv(\"datasets/traffic_collisions/pd_collisions_datasd_v1.csv\")\n",
    "\n",
    "# Read police calls in 2015, 2016, 2017, 2018, and 2019 into seperate Data Frames\n",
    "df_police_calls1 = pd.read_csv(\"datasets/police_calls/pd_calls_for_service_2015_datasd_v1.csv\")\n",
    "df_police_calls2 = pd.read_csv(\"datasets/police_calls/pd_calls_for_service_2016_datasd_v1.csv\")\n",
    "df_police_calls3 = pd.read_csv(\"datasets/police_calls/pd_calls_for_service_2017_datasd_v1.csv\")\n",
    "df_police_calls4 = pd.read_csv(\"datasets/police_calls/pd_calls_for_service_2018_datasd.csv\")\n",
    "df_police_calls5 = pd.read_csv(\"datasets/police_calls/pd_calls_for_service_2019_datasd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_num</th>\n",
       "      <th>date_time</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>address_number_primary</th>\n",
       "      <th>address_dir_primary</th>\n",
       "      <th>address_road_primary</th>\n",
       "      <th>address_sfx_primary</th>\n",
       "      <th>address_dir_intersecting</th>\n",
       "      <th>address_road_intersecting</th>\n",
       "      <th>address_sfx_intersecting</th>\n",
       "      <th>call_type</th>\n",
       "      <th>disposition</th>\n",
       "      <th>beat</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P15010000001</td>\n",
       "      <td>2015-01-01 00:00:14</td>\n",
       "      <td>3</td>\n",
       "      <td>3800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AU1</td>\n",
       "      <td>K</td>\n",
       "      <td>4.4e+02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P15010000002</td>\n",
       "      <td>2015-01-01 00:00:30</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60TH</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEDERAL</td>\n",
       "      <td>BL</td>\n",
       "      <td>AU1</td>\n",
       "      <td>DUP</td>\n",
       "      <td>4.3e+02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P15010000003</td>\n",
       "      <td>2015-01-01 00:00:48</td>\n",
       "      <td>3</td>\n",
       "      <td>3600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOGAN</td>\n",
       "      <td>AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AU1</td>\n",
       "      <td>DUP</td>\n",
       "      <td>4.4e+02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P15010000004</td>\n",
       "      <td>2015-01-01 00:00:57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33RD</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IMPERIAL</td>\n",
       "      <td>AV</td>\n",
       "      <td>AU1</td>\n",
       "      <td>K</td>\n",
       "      <td>5.1e+02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P15010000005</td>\n",
       "      <td>2015-01-01 00:01:05</td>\n",
       "      <td>3</td>\n",
       "      <td>3300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43RD</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AU1</td>\n",
       "      <td>O</td>\n",
       "      <td>8.3e+02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   incident_num            date_time  day_of_week  address_number_primary  \\\n",
       "0  P15010000001  2015-01-01 00:00:14            3                    3800   \n",
       "1  P15010000002  2015-01-01 00:00:30            3                       0   \n",
       "2  P15010000003  2015-01-01 00:00:48            3                    3600   \n",
       "3  P15010000004  2015-01-01 00:00:57            3                       0   \n",
       "4  P15010000005  2015-01-01 00:01:05            3                    3300   \n",
       "\n",
       "  address_dir_primary address_road_primary address_sfx_primary  \\\n",
       "0                 NaN                DELTA                  ST   \n",
       "1                 NaN                 60TH                  ST   \n",
       "2                 NaN                LOGAN                  AV   \n",
       "3                 NaN                 33RD                  ST   \n",
       "4                 NaN                 43RD                  ST   \n",
       "\n",
       "  address_dir_intersecting address_road_intersecting address_sfx_intersecting  \\\n",
       "0                      NaN                       NaN                      NaN   \n",
       "1                      NaN                   FEDERAL                       BL   \n",
       "2                      NaN                       NaN                      NaN   \n",
       "3                      NaN                  IMPERIAL                       AV   \n",
       "4                      NaN                       NaN                      NaN   \n",
       "\n",
       "  call_type disposition     beat priority  \n",
       "0       AU1           K  4.4e+02        1  \n",
       "1       AU1         DUP  4.3e+02        1  \n",
       "2       AU1         DUP  4.4e+02        1  \n",
       "3       AU1           K  5.1e+02        1  \n",
       "4       AU1           O  8.3e+02        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging police calls in 2015,2016,2017,2018,2019 into one Data Frame \n",
    "df_police_calls = pd.concat([df_police_calls1, df_police_calls2,df_police_calls3,df_police_calls4,df_police_calls5])\n",
    "\n",
    "# check that the Data Frames were merged properly\n",
    "df_police_calls.head()  # shows 2015 data\n",
    "# df_police_calls.tail() # shows 2019 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic Collisions\n",
    "\n",
    "# Returns the current structure, shape, column names, and data type of each column\n",
    "# df_collisions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic Collisions\n",
    "\n",
    "# Date Time\n",
    "\n",
    "# Creating seperate columns for Date and Time\n",
    "date_time = df_collisions['date_time'].str.split(' ', n=1, expand=True)\n",
    "df_collisions = df_collisions.drop(['date_time'], axis=1)\n",
    "df_collisions['date'] = date_time[0]\n",
    "df_collisions['time'] = date_time[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the 'date' and 'time' columns to datetime data types \n",
    "df_collisions['date']= pd.to_datetime(df_collisions['date']) \n",
    "df_collisions['time']= pd.to_datetime(df_collisions['time'])\n",
    "\n",
    "# Checking that columns 'date' and 'time' are now datetime objects\n",
    "\n",
    "# assert isinstance(df_collisions.date,datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic Collisions\n",
    "\n",
    "# droping useless columns\n",
    "drop_cols_collision = ['address_pd_primary','address_pd_intersecting', 'address_name_intersecting', 'address_sfx_intersecting','report_id']\n",
    "df_collisions = df_collisions.drop(drop_cols_collision, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic Collisions\n",
    "\n",
    "\n",
    "# Changing datatype of address_number_primary from int to str\n",
    "df_collisions['address_number_primary'] = df_collisions.address_number_primary.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic Collisions\n",
    "\n",
    "# String manipulations\n",
    "\n",
    "# Making everything lowercase\n",
    "df_collisions['address_road_primary'] = df_collisions['address_road_primary'].str.lower()\n",
    "df_collisions['address_sfx_primary'] = df_collisions['address_sfx_primary'].str.lower()\n",
    "df_collisions['charge_desc'] = df_collisions['charge_desc'].str.lower()\n",
    "df_collisions['hit_run_lvl'] = df_collisions['hit_run_lvl'].str.lower()\n",
    "\n",
    "#stripping gets rid of extraneous spaces to allow for easier processing of data\n",
    "df_collisions['address_road_primary'] = df_collisions.address_road_primary.str.strip()\n",
    "df_collisions['address_sfx_primary'] = df_collisions.address_sfx_primary.str.strip()\n",
    "df_collisions['violation_section']= df_collisions.violation_section.str.strip()\n",
    "df_collisions['violation_type'] = df_collisions.violation_type.str.strip()\n",
    "df_collisions['charge_desc'] = df_collisions.charge_desc.str.strip()\n",
    "df_collisions['hit_run_lvl'] = df_collisions.hit_run_lvl.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_police calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Police Calls\n",
    "\n",
    "# Change entries in col 'day_of_week' to represent the day of the week in words\n",
    "df_police_calls['day_of_week'] = df_police_calls['day_of_week'].replace(1,'Monday')\n",
    "df_police_calls['day_of_week'] = df_police_calls['day_of_week'].replace(2,'Tuesday')\n",
    "df_police_calls['day_of_week'] = df_police_calls['day_of_week'].replace(3,'Wednesday')\n",
    "df_police_calls['day_of_week'] = df_police_calls['day_of_week'].replace(4,'Thursday')\n",
    "df_police_calls['day_of_week'] = df_police_calls['day_of_week'].replace(5,'Friday')\n",
    "df_police_calls['day_of_week'] = df_police_calls['day_of_week'].replace(6,'Saturday')\n",
    "df_police_calls['day_of_week'] = df_police_calls['day_of_week'].replace(7,'Sunday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Police Calls\n",
    "\n",
    "# Date Time\n",
    "\n",
    "# Creating seperate columns for Date and Time\n",
    "date_time = df_police_calls['date_time'].str.split(' ', n=1, expand=True)\n",
    "df_police_calls = df_police_calls.drop(['date_time'], axis=1)\n",
    "df_police_calls['date'] = date_time[0]\n",
    "df_police_calls['time'] = date_time[1]\n",
    "\n",
    "# convert the 'Date' column to datetime format \n",
    "df_police_calls['date']= pd.to_datetime(df_police_calls['date']) \n",
    "df_police_calls['time']= pd.to_datetime(df_police_calls['time']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing datatype of address_number_primary from int to str\n",
    "df_police_calls['address_number_primary'] = df_police_calls.address_number_primary.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Police Calls\n",
    "\n",
    "# dropping useless columns\n",
    "drop_cols_calls = ['address_dir_primary', 'address_dir_intersecting','incident_num']\n",
    "df_police_calls = df_police_calls.drop(drop_cols_calls,axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Police Calls\n",
    "\n",
    "# String manipulations\n",
    "\n",
    "# making everything lowercase\n",
    "df_police_calls['address_road_primary']=df_police_calls['address_road_primary'].str.lower()\n",
    "df_police_calls['address_road_intersecting']=df_police_calls['address_road_intersecting'].str.lower()\n",
    "df_police_calls['address_sfx_primary'] = df_police_calls['address_sfx_primary'].str.lower()\n",
    "\n",
    "# strip any extra spaces in string data\n",
    "df_police_calls['address_road_primary']= df_police_calls.address_road_primary.str.strip()\n",
    "df_police_calls['address_sfx_primary'] = df_police_calls.address_sfx_primary.str.strip()\n",
    "df_police_calls['address_road_intersecting']= df_police_calls.address_road_intersecting.str.strip()\n",
    "df_police_calls['call_type'] = df_police_calls.call_type.str.strip()\n",
    "df_police_calls['disposition'] = df_police_calls.disposition.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Police calls\n",
    "\n",
    "# Creating a single coulumn for primary address\n",
    "df_police_calls['Primary address']= df_police_calls.address_number_primary + ' ' + df_police_calls.address_road_primary + ' '+ df_police_calls.address_sfx_primary\n",
    "\n",
    "# Creating a single coulumn for intersecting address\n",
    "df_police_calls['Intersecting address'] = df_police_calls.address_road_intersecting+ ' '+ df_police_calls.address_sfx_intersecting\n",
    "\n",
    "# Dropping the newly useless columns\n",
    "cols_drop = ['address_number_primary','address_road_primary','address_sfx_primary','address_sfx_intersecting','address_road_intersecting']\n",
    "df_police_calls = df_police_calls.drop(cols_drop,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_police_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Police Stops\n",
    "\n",
    "drop_cols_stops = ['isstudent', 'gend_nc','agency','stop_id']\n",
    "df_police_stops = df_police_stops.drop(drop_cols_stops, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Police Stops\n",
    "\n",
    "# String manipulations\n",
    "\n",
    "# making everything lowercase\n",
    "df_police_stops['address_city'] = df_police_stops['address_city'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial tools\n",
    "- Geojson: https://pypi.org/project/geojson/\n",
    "    - https://www.datacamp.com/community/tutorials/geospatial-data-python\n",
    "- GeoPandas: http://geopandas.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualization tools: https://medium.com/@stallonejacob/d3-in-juypter-notebook-685d6dca75c8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
